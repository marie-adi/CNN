{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd385d3",
   "metadata": {},
   "source": [
    "# Redes neuronales convolucionales o CNNs.\n",
    "\n",
    "**¿Qué es una red neuronal?**\n",
    "\n",
    "En el campo del **aprendizaje automático**, las **redes neuronales artificiales** se erigen como un paradigma computacional inspirado en la estructura y el funcionamiento del cerebro humano. Su arquitectura se basa en la interconexión de **nodos**, a menudo denominados **\"neuronas\"**, organizados en capas. Estas neuronas procesan la información de entrada, la transforman a través de una función no lineal y la transmiten a la siguiente capa.\n",
    "\n",
    "## La Estructura y el Aprendizaje\n",
    "\n",
    "Se compone de tres tipos de capas:\n",
    "\n",
    "- **Capa de entrada (Input Layer):** Recibe los datos iniciales, como los píxeles de una imagen o los valores de una tabla. Cada neurona en esta capa corresponde a una característica de entrada.\n",
    "\n",
    "- **Capas ocultas (Hidden Layers):** Aquí se realiza la mayor parte del procesamiento. Las neuronas en estas capas reciben la salida de la capa anterior, aplican una **suma ponderada** de las entradas (donde los \"pesos\" son los parámetros del modelo) y luego pasan el resultado a una **función de activación** para introducir no linealidad.\n",
    "\n",
    "- **Capa de salida (Output Layer):** Produce el resultado final del modelo, que puede ser una clasificación (como \"gato\" o \"perro\") o una regresión (un valor numérico).\n",
    "\n",
    "El proceso de **aprendizaje** en una RNA es iterativo y se basa en la **optimización**. El modelo se entrena alimentándole un conjunto de datos, ajustando los pesos de las conexiones entre neuronas para minimizar una **función de pérdida**. Esta función cuantifica la discrepancia entre la salida predicha del modelo y el valor real.\n",
    "\n",
    "<img src=\"src/images/EsquemaRNA.png\">\n",
    "\n",
    "Las redes neuronales tradicionales son muy buenas para datos como tablas o series de tiempo, pero cuando se trata de imágenes... tienen un gran problema. Y ahí es donde entran las CNNs.\n",
    "\n",
    "---\n",
    "\n",
    "## El problema de las imágenes\n",
    "\n",
    "Aunque las redes neuronales son extremadamente potentes, presentan serios inconvenientes cuando se aplican directamente al **procesamiento de imágenes**.\n",
    "\n",
    "¿Por qué no podemos usar una red neuronal normal para imágenes? Hay dos razones principales:\n",
    "\n",
    "**1. El problema de la dimensionalidad.**\n",
    "\n",
    "Las imágenes son datos de alta dimensión, una foto simple de 200x200 píxeles. ¡Eso son 40,000 píxeles! Si la imagen es a color, multiplicamos por 3 (para los canales rojo, verde y azul). Ya tenemos 120,000 datos de entrada. Si la primera capa tuviera 1,000 neuronas, necesitaríamos **120 millones de conexiones** solo para la primera capa. Este número de parámetros hace que el modelo sea computacionalmente inviable, propenso al sobreajuste y difícil de entrenar.\n",
    "\n",
    "**2. Pérdida de la Estructura Espacial:**\n",
    "Una red neuronal tradicional \"aplana\" la imagen, convirtiendo la cuadrícula 2D en una sola línea de píxeles. Al aplanar la imagen en un vector de una sola dimensión para su entrada hace que pierda una información crucial: se elimina por completo la información de la **vecindad espacial** entre los píxeles. Esto significa que la red pierde la capacidad de reconocer patrones locales, como bordes, texturas o formas, que son fundamentales para la visión. saber qué píxeles están juntos es fundamental para detectar un ojo, una nariz o una oreja. Si los aplanamos, perdemos esa información.\n",
    "\n",
    "Las **Redes Neuronales Convolucionales (CNN)** surgieron como una solución a estos problemas, introduciendo un enfoque que respeta la estructura espacial de las imágenes y reduce drásticamente el número de parámetros.\n",
    "\n",
    "---\n",
    "\n",
    "## Los bloques de construcción de una CNN\n",
    "\n",
    "Las CNNs usan tres tipos de capas para procesar las imágenes de una forma más inteligente.\n",
    "\n",
    "### 1. La Capa de Convolución (Convolutional Layer)\n",
    "\n",
    "La capa de convolución es el núcleo de la CNN y la principal responsable de la extracción de características. La operación de **convolución** es una operación matemática lineal que consiste en la aplicación de un **filtro** (también conocido como *kernel* o mapa de características) a una matriz de entrada, en este caso, la imagen.\n",
    "\n",
    "El filtro es una pequeña matriz de pesos que se desliza por la imagen de entrada con un paso o **zancada (*stride*)** predefinido. En cada posición, el filtro realiza un producto punto (*dot product*) con la porción de la imagen que cubre, y la suma de estos productos se registra en una nueva matriz, conocida como **mapa de características** o **mapa de activación**. Este proceso se repite hasta que el filtro ha recorrido toda la imagen.\n",
    "\n",
    "La principal ventaja de este método es la **compartición de pesos (*weight sharing*)**. El mismo filtro (con sus mismos pesos) se aplica a toda la imagen, lo que significa que la red puede detectar la misma característica (por ejemplo, un borde vertical) en cualquier lugar de la imagen sin necesidad de aprender un nuevo conjunto de pesos para cada ubicación. Esto reduce drásticamente el número de parámetros del modelo, mitigando el riesgo de sobreajuste y mejorando la eficiencia computacional.\n",
    "\n",
    "Para manejar los límites de la imagen y asegurar que el mapa de características tenga un tamaño deseado, se puede usar **relleno (*padding*)**. El relleno implica añadir filas y columnas de ceros alrededor de la imagen de entrada.\n",
    "\n",
    "<img src=\"src/images/02.png\">\n",
    "<img src=\"src/images/03.webp\">\n",
    "\n",
    "### 2. Capa de agrupación (Pooling Layer)\n",
    "\n",
    "Tras la operación de convolución y la aplicación de una función de activación no lineal (comúnmente la **Rectified Linear Unit o ReLU**), se utiliza la capa de *pooling*. Su función principal es reducir la dimensionalidad espacial (ancho y alto) del mapa de características, lo que a su vez disminuye la carga computacional y el número de parámetros.\n",
    "\n",
    "La operación de *pooling* más utilizada es el **Max Pooling**. Consiste en dividir el mapa de características en una serie de cuadrículas (por ejemplo, de 2x2) y, para cada cuadrícula, seleccionar el valor máximo. El resultado es un mapa de características más pequeño que mantiene las características más importantes o \"activadas\".\n",
    "\n",
    "Las principales ventajas del *pooling* son:\n",
    "\n",
    "- **Reducción de la dimensionalidad:** Disminuye el número de parámetros, lo que hace el entrenamiento más rápido y previene el sobreajuste.\n",
    "- **Invarianza de traslación:** Al seleccionar el valor máximo de una región, la red se vuelve más robusta a las pequeñas traslaciones o desplazamientos de los objetos en la imagen de entrada. Si una característica se mueve ligeramente, su valor máximo en la ventana de *pooling* probablemente se mantendrá.\n",
    "\n",
    "<img src=\"src/images/04.png\">\n",
    "\n",
    "### 3. Capa completamente conectada (Fully Connected Layer)\n",
    "\n",
    "Después de varias capas de convolución y *pooling*, los mapas de características han capturado patrones de alto nivel, como formas, texturas y componentes de objetos. Sin embargo, estas representaciones todavía tienen una estructura espacial que no es adecuada para una capa de clasificación estándar.\n",
    "\n",
    "La capa de convolución requiere una entrada en forma de vector de una dimensión. Para esto, se realiza una operación de **aplanamiento (*flattening*)**, donde los mapas de características 2D se reorganizan en un vector 1D. Este vector es entonces la entrada de una red neuronal densa o **capa completamente conectada**.\n",
    "\n",
    "Esta capa densa toma la salida de las capas anteriores (las \"características extraídas\") y las utiliza para realizar la clasificación final. Las capas densas aprenden a combinar estas características de alto nivel para producir un resultado de predicción, como la probabilidad de que la imagen pertenezca a cada una de las clases predefinidas (por ejemplo, \"gato\", \"perro\", \"pato\"). La capa de salida final típicamente utiliza una función de activación como **Softmax** para convertir los valores de salida en probabilidades.\n",
    "\n",
    "<img src=\"src/images/05.png\">\n",
    "\n",
    "## La arquitectura de una CNN\n",
    "\n",
    "### De la Detección de Características a la Clasificación\n",
    "\n",
    "La arquitectura de una CNN opera como un sistema de procesamiento jerárquico, donde cada capa sucesiva aprende a extraer características más complejas y abstractas de la imagen de entrada. A diferencia de un modelo de red densa, la estructura de una CNN está diseñada para preservar la información espacial, permitiendo el reconocimiento de patrones visuales.\n",
    "\n",
    "La arquitectura se puede dividir en dos componentes principales: el **extractor de características** y el **clasificador**.\n",
    "\n",
    "### 1. El Extractor de Características\n",
    "\n",
    "Este componente, que constituye la mayor parte de la red, está compuesto por una secuencia de bloques, cada uno conteniendo una **capa de convolución**, seguida de una **función de activación** (como ReLU) y una **capa de *pooling***.\n",
    "\n",
    "- **Primeras capas:** Las primeras capas convolucionales se centran en la detección de características de **bajo nivel**, como bordes, esquinas y texturas simples. Sus filtros, de pequeño tamaño, actúan como detectores de características primitivas.\n",
    "- **Capas intermedias y profundas:** A medida que la información avanza a través de la red, las capas más profundas aprenden a combinar las características de bajo nivel para formar representaciones más complejas y de **alto nivel**. Por ejemplo, combinando bordes y curvas se pueden detectar formas como ojos, narices o ruedas. Esta progresión jerárquica es una de las mayores fortalezas de las CNN, ya que permite que la red aprenda a reconocer objetos enteros a partir de sus partes constituyentes.\n",
    "\n",
    "### 2. El Clasificador\n",
    "\n",
    "Una vez que el extractor de características ha producido una representación rica y compacta de la imagen, esta representación necesita ser interpretada para realizar la clasificación. Aquí es donde entran las capas densamente conectadas.\n",
    "\n",
    "- **Aplanamiento (*Flattening*):** Antes de alimentar la información a la capa densa, los mapas de características 2D se \"aplanan\" en un vector unidimensional. Este vector encapsula todas las características extraídas por las capas convolucionales, pero sin la estructura espacial.\n",
    "- **Capas Totalmente Conectadas (Fully Connected Layers):** Este vector de características se convierte en la entrada de una o más capas totalmente conectadas. Estas capas, similares a las de una red neuronal tradicional, aprenden a ponderar la importancia de cada característica para la tarea de clasificación.\n",
    "- **Capa de Salida:** La capa final de la red totalmente conectada produce la predicción. En un problema de clasificación de múltiples clases, esta capa suele utilizar una función de activación **softmax** para generar un vector de probabilidades, donde cada elemento representa la probabilidad de que la imagen pertenezca a una clase específica. La clase con la probabilidad más alta es la predicción final del modelo.\n",
    "\n",
    "Esta arquitectura modular y jerárquica permite que las CNNs sean excepcionalmente eficientes y precisas en una amplia gama de tareas de visión por computadora.\n",
    "\n",
    "<img src=\"src/images/06.png\">\n",
    "<img src=\"src/images/07.png\">\n",
    "---\n",
    "\n",
    "### Aplicaciones en el mundo real\n",
    "\n",
    "Las CNNs han revolucionado la **visión por computadora**. Hoy en día, las encontramos en:\n",
    "\n",
    "- **Vehículos autónomos:** Para detectar otros coches, peatones y señales de tráfico.\n",
    "- **Seguridad:** Reconocimiento facial en aeropuertos o teléfonos.\n",
    "- **Medicina:** Diagnóstico de enfermedades a partir de resonancias magnéticas o radiografías.\n",
    "- **Tecnología:** El etiquetado automático de fotos en Google Photos o Facebook.\n",
    "- Entre otros sectores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df28494",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "**Medios digitales:**\n",
    "\n",
    "https://www.researchgate.net/publication/326068293_Deteccion_de_cambios_en_la_cobertura_vegetal_mediante_interpretacion_de_imagenes_Landsat_por_redes_neuronales_artificiales_RNA_Caso_de_estudio_Region_Amazonica_Ecuatoriana\n",
    "https://medium.com/analytics-vidhya/convolution-operations-in-cnn-deep-learning-compter-vision-128906ece7d3\n",
    "https://www.researchgate.net/publication/340812216_Deep_Neural_Networks_on_Chip_-_A_Survey\n",
    "https://www.researchgate.net/publication/360069326_Classification_of_Eeg_Signals_Using_Transfer_Learning_on_Convolutional_Neural_Networks_via_Spectrogram\n",
    "https://www.researchgate.net/publication/331165618_Going_Deep_in_Medical_Image_Analysis_Concepts_Methods_Challenges_and_Future_Directions\n",
    "https://learnopencv.com/understanding-convolutional-neural-networks-cnn/\n",
    "https://www.researchgate.net/publication/281607765_Hierarchical_Deep_Learning_Architecture_For_10K_Objects_Classification\n",
    "https://www.researchgate.net/publication/340082803_Deep_Learning_Exemplar_Studies_in_Natural_Language_Processing_and_Computer_Vision\n",
    "https://www.researchgate.net/publication/344877256_Real_time_Face_detection_and_Emotion_and_Gender_Classification_Using_Convolutional_Neural_Network\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
